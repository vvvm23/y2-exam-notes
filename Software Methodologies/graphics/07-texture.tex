\documentclass[../graphics.tex]{subfiles}

\begin{document}

Texture Mapping is a method for adding surface details such as colour and patterns over the surface of a 3D model. Relying on mesh geometry to add details is expensive. Our goal is to instead associated 2D information with a 3D surface by mapping points on a texture to points on a 3D model.
\\

A Texture image is a 2D array of colour values, known as texels. We assign texture coordinates at each vertex of an object and interpolate between them to get a colour value for every fragment.

We don't have to use the entire texture for a single object. In fact, it is often better to create one texture (an atlas) containing sub-images, each of which is a texture.
\\

In computer graphic applications there are multiple coordinate systems:

\begin{itemize}
    \item \textbf{Parametric Coordinates} -- A coordinate system for processing the surface and the internal space of a 3D object.
    \item \textbf{Texture Coordinates} -- Used to identify points in the image to be mapped.
    \item \textbf{Local or World Coordinates} -- Used to position 3D objects.
    \item \textbf{Window Coordinates} -- Where the final output image is produced.
\end{itemize}
\\

There are two forms of texture mapping:
\\

\textbf{Forward Texture Mapping} -- Mapping from texture coordinates to points on a surface.

This has the issue of adjacent texture points may project onto non-adjacent image points and so creating a non-coloured area.
\\

\textbf{Backward Texture Mapping} -- Mapping a point on an object to texture coordinates.

This ensures every object point has a corresponding texel, however these functions are difficult to find in general cases.
\\

For more complex shapes, texture mapping coordinates is difficult. We can simplify the process by separating it into two parts. One is to map the texture to a simpler intermediate surface which is then mapped to the object.

For example, mapping to a parametric sphere from the texture map and then into he final shape.
\\

MIP-Mapping is a technique where an original, high-resolution texture is scaled and filtered into multiple lower resolutions within a single texture file. Each scaled texture represents what the texture would look like at a specific distance from the viewpoint. This imitates the natural representation of how colours and details blend together at a distance.

It also helps solve aliasing problems when high resolution textures are used at a distance, leading to unsightly patterns.
\\

We can also provide a normal mapping alongside the texture to represent the normal vectors at different points along a texture. This alters the surface normal but does not change the actual shape of the surface and so does not increase geometric complexity.
\\

We can can also provide a bump map instead of a normal map. This encodes the heights of the surface. The heights encode the amount by which to perturb the surface in order to describe the object's surface. 

A bump map will modify the geometric normal whereas a normal map replaces the normal. The former is harder to implement but easier to specify. Vice versa for normal maps.

\textit{A normal map is a type of bump map.}

\\

A final alternative is to use a displacement mapping. This actually alters the geometry. The new geometry must be displaced before visibility is determined so must be done as a preprocessing step.

\textit{In other words, displacement mapping alters the geometry wheras bump mapping only modifies the surface of a piece of geometry.}

\textit{The difference between displacement and normal maps becomes apparent when viewed edge on: normal mapped surfaces will appear flat wheras displacement will have detail.}

\textit{Essentially, normal and bump maps create the appearance of surface detail by changing the normals wheras displacement maps actually add new geometry at render time.}
\\

We can use environment maps to simulate reflections by using the direction of the reflected ray to index a spherical texture map at infinity.

\textit{For example, place a camera with a 360 field of view and map its viewport to this spherical texture map at infinity. Then draw on the object based on the view point angle and where it is looking on the object.}
\\

We can use light maps to illuminate parts of the texture to produce realistic lighting. Lighting calculation ca be done in preprocessing time and during run time only colour arithmetic needs to be done. This makes it faster than usual lighting methods. The visual quality of the lighting is directly dependent on the size of the light map texture.

The light maps for different parts of an object can be packed into a single large texture known as a lightmap texture.
\\

A dynamic modification of light-maps is fog map. Place fog objects in a scene and compute where they intersect with geometry and so create a dynamic light map based on fog density. 

\end{document}
